import ast
import io
import re
import json
import logging
import time
from typing import Dict, Optional

import google.generativeai as genai
from django.conf import settings
from groq import Groq

logger = logging.getLogger(__name__)


class EnhancedAIService:
    """
    –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç–∞—è AI-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏.
    –í–∫–ª—é—á–∞–µ—Ç: NLU, –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ, –∞–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π, –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö.
    """

    def __init__(self, text_provider: Optional[str] = None):
        self.text_provider = (text_provider or getattr(settings, "AI_TEXT_PROVIDER", "gemini")).lower()

        groq_key = getattr(settings, 'GROQ_API_KEY', None)
        self.client = Groq(api_key=groq_key) if groq_key else None
        self.text_model = getattr(settings, "GROQ_TEXT_MODEL", "llama-3.3-70b-versatile")
        self.audio_model = getattr(settings, "GROQ_AUDIO_MODEL", "whisper-large-v3-turbo")

        self.gemini_text_model = getattr(settings, "GEMINI_TEXT_MODEL", "gemini-2.5-flash")
        self.gemini_json_model = getattr(settings, "GEMINI_JSON_MODEL", "gemini-1.5-flash")
        self.gemini_model = None
        self.gemini_json_model_client = None

        embedding_key = getattr(settings, 'GEMINI_API_KEY', None)
        if embedding_key:
            genai.configure(api_key=embedding_key)
            self.gemini_model = genai.GenerativeModel(self.gemini_text_model)
            self.gemini_json_model_client = genai.GenerativeModel(self.gemini_json_model)

        # –ö—ç—à –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
        self._location_cache = {}
        self._quota_exceeded = False

    def _generate_with_retry(self, prompt: str, retries=3, temperature=0.3, json_mode=False):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä —Å retry –ª–æ–≥–∏–∫–æ–π"""
        if self.text_provider == "groq":
            return self._generate_with_retry_groq(prompt, retries, temperature, json_mode)
        return self._generate_with_retry_gemini(prompt, retries, temperature, json_mode)

    def _generate_with_retry_groq(self, prompt: str, retries=3, temperature=0.3, json_mode=False):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Groq —Å retry –ª–æ–≥–∏–∫–æ–π"""
        force_json = bool(json_mode)
        for attempt in range(retries):
            try:
                if not self.client:
                    raise RuntimeError("GROQ_API_KEY is not configured")

                messages = [
                    {
                        "role": "system",
                        "content": "Return a valid JSON object only. No extra text." if force_json else "You are a helpful assistant."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]

                request_kwargs = {
                    "model": self.text_model,
                    "messages": messages,
                    "temperature": temperature,
                    "top_p": 0.95,
                    "max_tokens": 2048,
                }
                if force_json:
                    request_kwargs["response_format"] = {"type": "json_object"}

                response = self.client.chat.completions.create(**request_kwargs)
                return response
            except Exception as e:
                wait_time = 5 * (attempt + 1)
                error_text = str(e)
                if force_json and "response_format" in error_text.lower():
                    logger.warning("Groq response_format not supported, retrying without JSON mode")
                    force_json = False
                elif "429" in error_text or "rate" in error_text.lower():
                    logger.warning(f"Groq rate limit. Retry {attempt + 1}/{retries} after {wait_time}s")
                else:
                    logger.error(f"Groq error: {e}")
                if attempt == retries - 1:
                    self._quota_exceeded = True
                    return None
                time.sleep(wait_time)
        return None

    def _generate_with_retry_gemini(self, prompt: str, retries=3, temperature=0.3, json_mode=False):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Gemini —Å retry –ª–æ–≥–∏–∫–æ–π"""
        for attempt in range(retries):
            try:
                if not self.gemini_model:
                    raise RuntimeError("GEMINI_API_KEY is not configured")

                model = self.gemini_json_model_client if json_mode else self.gemini_model
                config = genai.types.GenerationConfig(
                    temperature=temperature,
                    top_p=0.95,
                    top_k=40,
                    max_output_tokens=4096,
                    response_mime_type="application/json" if json_mode else "text/plain"
                )
                response = model.generate_content(prompt, generation_config=config)
                return response
            except Exception as e:
                wait_time = 5 * (attempt + 1)
                error_text = str(e)
                if "429" in error_text or "rate" in error_text.lower():
                    logger.warning(f"Gemini rate limit. Retry {attempt + 1}/{retries} after {wait_time}s")
                else:
                    logger.error(f"Gemini error: {e}")
                if attempt == retries - 1:
                    self._quota_exceeded = True
                    return None
                time.sleep(wait_time)
        return None

    def consume_quota_error(self) -> bool:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ quota –±—ã–ª–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∞, –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ñ–ª–∞–≥."""
        if self._quota_exceeded:
            self._quota_exceeded = False
            return True
        return False

    @staticmethod
    def _extract_text(response) -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞"""
        if not response:
            return ""
        try:
            choices = getattr(response, "choices", [])
            if choices:
                message = getattr(choices[0], "message", None)
                if message and getattr(message, "content", None):
                    return message.content
            if getattr(response, "text", None):
                return response.text
        except Exception:
            logger.error("Failed to extract text from AI response")
        return ""

    def _parse_json_response(self, text: str) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ JSON —Å –ø–æ–∏—Å–∫–æ–º –≥—Ä–∞–Ω–∏—Ü –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Python-—Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞"""
        if not text:
            return None

        try:
            # 1. –ü–æ–∏—Å–∫ –≥—Ä–∞–Ω–∏—Ü JSON (—á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å "Here is your JSON..." –≤ –Ω–∞—á–∞–ª–µ)
            text = text.strip()

            # –ò—â–µ–º –∏–Ω–¥–µ–∫—Å—ã –Ω–∞—á–∞–ª–∞ –æ–±—ä–µ–∫—Ç–∞ –∏–ª–∏ —Å–ø–∏—Å–∫–∞
            start_brace = text.find('{')
            start_bracket = text.find('[')

            start = -1
            end = -1

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —á—Ç–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Ä–∞–Ω—å—à–µ (–æ–±—ä–µ–∫—Ç –∏–ª–∏ —Å–ø–∏—Å–æ–∫) –∏ –∏—â–µ–º –∫–æ–Ω–µ—Ü
            if start_brace != -1 and (start_bracket == -1 or start_brace < start_bracket):
                start = start_brace
                end = text.rfind('}') + 1
            elif start_bracket != -1 and (start_brace == -1 or start_bracket < start_brace):
                start = start_bracket
                end = text.rfind(']') + 1

            if start != -1 and end > start:
                json_str = text[start:end]
            else:
                # –ï—Å–ª–∏ —Å–∫–æ–±–æ–∫ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º —á–∏—Å—Ç–∏—Ç—å –∫–∞–∫ –±—ã–ª–æ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
                json_str = text.replace('```json', '').replace('```', '').strip()

            # 2. –ß–∏—Å—Ç–∫–∞ –≤–∏—Å—è—á–∏—Ö –∑–∞–ø—è—Ç—ã—Ö (Regex)
            json_str = re.sub(r',\s*]', ']', json_str)
            json_str = re.sub(r',\s*}', '}', json_str)

            # 3. –ü–æ–ø—ã—Ç–∫–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ JSON –ø–∞—Ä—Å–∏–Ω–≥–∞
            return json.loads(json_str)

        except json.JSONDecodeError:
            try:
                # 4. FALLBACK: Python eval
                # –°–ø–∞—Å–∞–µ—Ç, –µ—Å–ª–∏ AI –≤–µ—Ä–Ω—É–ª –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏: {'key': 'value'}
                return ast.literal_eval(json_str)
            except Exception:
                # 5. –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –û–®–ò–ë–ö–ò
                # –≠—Ç–æ —Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ: –º—ã —É–≤–∏–¥–∏–º –≤ –∫–æ–Ω—Å–æ–ª–∏, –∫–∞–∫–æ–π –∏–º–µ–Ω–Ω–æ —Ç–µ–∫—Å—Ç —Å–ª–æ–º–∞–ª –ø–∞—Ä—Å–µ—Ä
                logger.error(f"‚ùå JSON Parse Failed. Bad text content:\n{text}")
                return None
        except Exception as e:
            logger.error(f"‚ùå Unexpected Error in JSON parser: {e}")
            return None

    def transcribe_audio(self, audio_bytes: bytes, mime_type: str = "audio/mp3") -> str:
        """
        –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –∞—É–¥–∏–æ-—Ñ–∞–π–ª (–±–∞–π—Ç—ã) –≤ —Ç–µ–∫—Å—Ç.
        """
        if self.text_provider == "groq":
            return self._transcribe_audio_groq(audio_bytes, mime_type)
        return self._transcribe_audio_gemini(audio_bytes, mime_type)

    def _transcribe_audio_groq(self, audio_bytes: bytes, mime_type: str) -> str:
        try:
            if not self.client:
                raise RuntimeError("GROQ_API_KEY is not configured")

            logger.info("üé§ Sending audio to Groq for transcription...")

            if not isinstance(audio_bytes, (bytes, bytearray)):
                audio_bytes = bytes(audio_bytes)

            file_obj = io.BytesIO(audio_bytes)
            file_obj.name = "audio.mp3" if "mp3" in mime_type else "audio.ogg"

            response = self.client.audio.transcriptions.create(
                model=self.audio_model,
                file=file_obj,
                response_format="text"
            )

            text = str(response).strip()

            if not text:
                logger.warning("‚ö†Ô∏è Transcription returned empty content")
                return ""

            logger.info(f"üìù Transcription result: '{text}'")
            return text

        except Exception as e:
            error_text = str(e)
            logger.error(f"‚ùå Transcription failed: {e}")

            if "429" in error_text or "quota" in error_text.lower():
                return "__QUOTA_EXCEEDED__"

            return ""

    def _transcribe_audio_gemini(self, audio_bytes: bytes, mime_type: str) -> str:
        try:
            if not self.gemini_model:
                raise RuntimeError("GEMINI_API_KEY is not configured")

            logger.info("üé§ Sending audio to Gemini for transcription...")

            if not isinstance(audio_bytes, (bytes, bytearray)):
                audio_bytes = bytes(audio_bytes)

            prompt = "Listen to this audio and transcribe it exactly into Russian text. Do not add any commentary. Just the text."
            response = self.gemini_model.generate_content([
                prompt,
                {
                    "mime_type": mime_type,
                    "data": audio_bytes
                }
            ])

            text = ""
            try:
                text = response.text.strip()
            except Exception:
                text = ""

            if not text:
                logger.warning("‚ö†Ô∏è Transcription returned empty content")
                return ""

            logger.info(f"üìù Transcription result: '{text}'")
            return text

        except Exception as e:
            error_text = str(e)
            logger.error(f"‚ùå Transcription failed: {e}")

            if "429" in error_text or "quota" in error_text.lower():
                return "__QUOTA_EXCEEDED__"

            return ""

    # ======================== GEOGRAPHIC INTELLIGENCE ========================

    def resolve_location_intelligence(self, user_message: str, context: Dict = None) -> Dict:
        """
        –í—Ç–æ—Ä–æ–π —ç—Ç–∞–ø: –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞—Ü–∏–π.
        AI —Å–∞–º –ø–æ–Ω–∏–º–∞–µ—Ç EXPO, –õ–µ–≤—ã–π –±–µ—Ä–µ–≥, "—Ä—è–¥–æ–º —Å Mega" –∏ —Ç.–¥.
        """
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏, –ø–æ—ç—Ç–æ–º—É –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        context = context or {}
        cache_key = f"{user_message[:50]}_{context.get('city', '')}"
        if cache_key in self._location_cache:
            return self._location_cache[cache_key]

        context_info = json.dumps(context, ensure_ascii=False)

        prompt = f"""–¢—ã ‚Äî –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π AI-—ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≥–æ—Ä–æ–¥–∞–º –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞ (–ê—Å—Ç–∞–Ω–∞, –ê–ª–º–∞—Ç—ã, –®—ã–º–∫–µ–Ω—Ç, –ê—Ç—ã—Ä–∞—É).

–ó–ê–î–ê–ß–ê: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏ –æ–±–æ–≥–∞—Ç–∏—Ç—å –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–ì–û–†–û–î–ê (—Ç–æ–ª—å–∫–æ —ç—Ç–∏):
- Astana (–ê—Å—Ç–∞–Ω–∞, –ù—É—Ä—Å—É–ª—Ç–∞–Ω)
- Almaty (–ê–ª–º–∞—Ç—ã)
- Shymkent (–®—ã–º–∫–µ–Ω—Ç)
- Atyrau (–ê—Ç—ã—Ä–∞—É)

–ò–ó–í–ï–°–¢–ù–´–ï –†–ê–ô–û–ù–´ –ê–°–¢–ê–ù–´:
- –ï—Å–∏–ª—å—Å–∫–∏–π —Ä–∞–π–æ–Ω (–õ–µ–≤—ã–π –±–µ—Ä–µ–≥, Yesil, Esil) - –Ω–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä, EXPO, Mega Silk Way, –ë–∞–π—Ç–µ—Ä–µ–∫
- –°–∞—Ä—ã–∞—Ä–∫–∏–Ω—Å–∫–∏–π —Ä–∞–π–æ–Ω (–ü—Ä–∞–≤—ã–π –±–µ—Ä–µ–≥) - —Å—Ç–∞—Ä—ã–π –≥–æ—Ä–æ–¥, —Ä—ã–Ω–∫–∏
- –ê–ª–º–∞—Ç–∏–Ω—Å–∫–∏–π —Ä–∞–π–æ–Ω - –∂–∏–ª—ã–µ –º–∞—Å—Å–∏–≤—ã
- –ë–∞–π–∫–æ–Ω—É—Ä—Å–∫–∏–π —Ä–∞–π–æ–Ω - –ø—Ä–æ–º–∑–æ–Ω–∞, –∂–∏–ª—å–µ

–ò–ó–í–ï–°–¢–ù–´–ï –õ–û–ö–ê–¶–ò–ò –ê–°–¢–ê–ù–´:
- EXPO - –ï—Å–∏–ª—å—Å–∫–∏–π —Ä-–Ω, –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω—Ç—Ä, –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã ~51.091, 71.417
- Mega Silk Way - —Ä—è–¥–æ–º —Å EXPO
- –•–∞–Ω –®–∞—Ç—ã—Ä - —Ü–µ–Ω—Ç—Ä
- –ù–∞–∑–∞—Ä–±–∞–µ–≤ –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç - —Ä—è–¥–æ–º —Å EXPO
- –ë–æ—Ç–∞–Ω–∏—á–µ—Å–∫–∏–π —Å–∞–¥ - —Å–µ–≤–µ—Ä –≥–æ—Ä–æ–¥–∞

–ê–õ–ú–ê–¢–´:
- –ê–ª–º–∞–ª–∏–Ω—Å–∫–∏–π —Ä–∞–π–æ–Ω - —Ü–µ–Ω—Ç—Ä, –ê—Ä–±–∞—Ç
- –ú–µ–¥–µ—É—Å–∫–∏–π —Ä–∞–π–æ–Ω - —ç–ª–∏—Ç–Ω—ã–π, –≥–æ—Ä—ã
- –ë–æ—Å—Ç–∞–Ω–¥—ã–∫—Å–∫–∏–π - –¥–µ–ª–æ–≤–æ–π
- –ê—É—ç–∑–æ–≤—Å–∫–∏–π - –∂–∏–ª–æ–π –º–∞—Å—Å–∏–≤

–ü–†–ê–í–ò–õ–ê:
1. –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å < 0.4, –≤–æ–∑–≤—Ä–∞—â–∞–π city=null, district=null
2. EXPO –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ = Astana + –ï—Å–∏–ª—å—Å–∫–∏–π —Ä–∞–π–æ–Ω
3. "–õ–µ–≤—ã–π –±–µ—Ä–µ–≥" = Astana + –ï—Å–∏–ª—å—Å–∫–∏–π
4. –û—Ä–∏–µ–Ω—Ç–∏—Ä—ã (–ø–∞—Ä–∫, –º–µ—Ç—Ä–æ, –¢–¶) –¥–æ–±–∞–≤–ª—è–π –≤ nearby_landmarks
5. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∞–¥—Ä–µ—Å–∞ - —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å
6. –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ —É–∫–∞–∑–∞–Ω–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ ("500 –º–µ—Ç—Ä–æ–≤", "1 –∫–º") - –∑–∞–ø–æ–ª–Ω–∏ radius_km
7. –ï—Å–ª–∏ —É–ø–æ–º—è–Ω—É—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã–π –æ—Ä–∏–µ–Ω—Ç–∏—Ä (—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç, –¢–†–¶, –ø–∞—Ä–∫) ‚Äî –ø–æ–ø—Ä–æ–±—É–π —É–∫–∞–∑–∞—Ç—å coordinates_estimate
   (–¥–∞–∂–µ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ), –∏ –æ—Ç—Ä–∞–∑–∏ —ç—Ç–æ –≤ confidence

–ö–û–ù–¢–ï–ö–°–¢: {context_info}
–ó–ê–ü–†–û–°: "{user_message}"

–í–µ—Ä–Ω–∏ JSON:
{{
    "city": "Astana",
    "city_confidence": 0.95,
    "district": "–ï—Å–∏–ª—å—Å–∫–∏–π —Ä–∞–π–æ–Ω",
    "district_normalized": "Yesil District",
    "nearby_landmarks": ["EXPO", "Mega Silk Way"],
    "coordinates_estimate": {{"lat": 51.091, "lon": 71.417}},
    "radius_km": 5.0,
    "confidence": 0.88,
    "reasoning": "–£–ø–æ–º—è–Ω—É—Ç EXPO, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ï—Å–∏–ª—å—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ –ê—Å—Ç–∞–Ω—ã"
}}"""

        response = self._generate_with_retry(prompt, temperature=0.1, json_mode=True)
        text = self._extract_text(response)
        result = self._parse_json_response(text)
        if not result:
            retry_prompt = (
                "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –∫–æ–¥–∞ –∏ —Ç–µ–∫—Å—Ç–∞. "
                "–ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–π null/0.\n\n" + prompt
            )
            response = self._generate_with_retry(retry_prompt, temperature=0.0, json_mode=True)
            text = self._extract_text(response)
            result = self._parse_json_response(text)

        if not result or result.get('confidence', 0) < 0.4:
            return {
                "city": None,
                "district": None,
                "confidence": 0.0,
                "reasoning": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ª–æ–∫–∞—Ü–∏—é —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é"
            }

        self._location_cache[cache_key] = result
        return result

    # ======================== PARAMETER EXTRACTION ========================

    def extract_search_parameters(self, user_message: str, context: Dict = None) -> Dict:
        """
        –ß–µ—Ç–≤–µ—Ä—Ç—ã–π —ç—Ç–∞–ø: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ–∏—Å–∫–∞.
        –¶–µ–Ω–∞, –∫–æ–º–Ω–∞—Ç—ã, –ø–ª–æ—â–∞–¥—å –∏ —Ç.–¥.
        """
        context_info = json.dumps(context or {}, ensure_ascii=False)

        prompt = f"""–¢—ã ‚Äî AI-–∞–Ω–∞–ª–∏—Ç–∏–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏.

–ò–ó–í–õ–ï–ö–ê–ï–ú–´–ï –ü–ê–†–ê–ú–ï–¢–†–´:
1. rooms (int) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç (1, 2, 3, 4+)
2. min_price / max_price (int) - –±—é–¥–∂–µ—Ç –≤ —Ç–µ–Ω–≥–µ
3. min_area / max_area (float) - –ø–ª–æ—â–∞–¥—å –≤ –º¬≤
4. floor_preferences (list) - –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ —ç—Ç–∞–∂—É ["not_first", "not_last", "high"]
5. property_type (str) - "new_building", "secondary", "any"

–†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–ï –§–û–†–ú–£–õ–ò–†–û–í–û–ö:
- "–¥–≤—É—à–∫–∞" = 2 –∫–æ–º–Ω–∞—Ç—ã
- "–¥–æ 50 –ª—è–º–æ–≤" = max_price: 50000000
- "40-50 –∫–≤–∞–¥—Ä–∞—Ç–æ–≤" = min_area: 40, max_area: 50
- "–Ω–µ –ø–µ—Ä–≤—ã–π —ç—Ç–∞–∂" = floor_preferences: ["not_first"]

–ö–û–ù–¢–ï–ö–°–¢: {context_info}
–ó–ê–ü–†–û–°: "{user_message}"

–í–µ—Ä–Ω–∏ JSON:
{{
    "rooms": 2,
    "max_price": 50000000,
    "min_area": 40,
    "max_area": 60,
    "floor_preferences": ["not_first"],
    "property_type": "any",
    "confidence": 0.85,
    "extracted_entities": {{"rooms": "–¥–≤—É—à–∫–∞", "price": "–¥–æ 50 –º–ª–Ω"}}
}}"""

        response = self._generate_with_retry(prompt, temperature=0.2, json_mode=True)
        text = self._extract_text(response)
        result = self._parse_json_response(text)
        if not result:
            retry_prompt = (
                "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –∫–æ–¥–∞ –∏ —Ç–µ–∫—Å—Ç–∞. "
                "–ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–π null/0.\n\n" + prompt
            )
            response = self._generate_with_retry(retry_prompt, temperature=0.0, json_mode=True)
            text = self._extract_text(response)
            result = self._parse_json_response(text)

        return result or {"confidence": 0.0}

    # ======================== EMBEDDINGS ========================

    def get_embedding(self, text: str):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        try:
            if not getattr(settings, 'GEMINI_API_KEY', None):
                logger.warning("‚ö†Ô∏è GEMINI_API_KEY is not configured, embeddings disabled")
                return None
            embedding_model = getattr(settings, "EMBEDDING_MODEL", "models/text-embedding-004")
            result = genai.embed_content(
                model=embedding_model,
                content=text,
                task_type="retrieval_document"
            )
            embedding = result.get('embedding')

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ truth value –¥–ª—è numpy array
            if embedding is None:
                return None

            embedding = list(embedding)
            expected_dim = getattr(settings, "EMBEDDING_DIMENSIONS", 768)
            if len(embedding) != expected_dim:
                logger.warning(
                    f"‚ö†Ô∏è Embedding dimension mismatch: got {len(embedding)}, expected {expected_dim}. "
                    "Auto-adjusting."
                )
                if len(embedding) > expected_dim:
                    embedding = embedding[:expected_dim]
                else:
                    embedding = embedding + [0.0] * (expected_dim - len(embedding))

            return embedding
        except Exception as e:
            logger.error(f"Embedding error: {e}")
            return None

    # ======================== CONSULTATION (RAG) ========================

    def generate_consultation(self, query: str, location_info: Dict = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ø–æ —Ä–∞–π–æ–Ω—É"""
        location_context = json.dumps(location_info or {}, ensure_ascii=False)

        prompt = f"""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞.

–ö–û–ù–¢–ï–ö–°–¢ –õ–û–ö–ê–¶–ò–ò: {location_context}
–í–û–ü–†–û–°: "{query}"

–î–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é:
1. –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–π–æ–Ω–∞/–ª–æ–∫–∞—Ü–∏–∏
2. –ü–ª—é—Å—ã (3-4 –ø—É–Ω–∫—Ç–∞)
3. –ú–∏–Ω—É—Å—ã (2-3 –ø—É–Ω–∫—Ç–∞)
4. –î–ª—è –∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∏—Ç
5. –°—Ä–µ–¥–Ω–∏–µ —Ü–µ–Ω—ã (–µ—Å–ª–∏ –∑–Ω–∞–µ—à—å)

–°—Ç–∏–ª—å: –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç, —á–µ—Å—Ç–Ω—ã–π, –±–µ–∑ –ø—Ä–µ—É–≤–µ–ª–∏—á–µ–Ω–∏–π."""

        response = self._generate_with_retry(prompt, temperature=0.6)
        return self._extract_text(response) or "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é."
