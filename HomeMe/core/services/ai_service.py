import ast
import re

import google.generativeai as genai
from google.api_core import exceptions
import json
import logging
import time
from typing import Dict, List, Optional, Tuple
from django.conf import settings

logger = logging.getLogger(__name__)


class EnhancedAIService:
    """
    –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç–∞—è AI-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏.
    –í–∫–ª—é—á–∞–µ—Ç: NLU, –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ, –∞–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π, –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö.
    """

    def __init__(self):
        api_key = getattr(settings, 'GEMINI_API_KEY')
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.5-flash')

        print("üîç –ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...\n")

        try:
            for m in genai.list_models():
                # –ù–∞–º –Ω—É–∂–Ω—ã —Ç–æ–ª—å–∫–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ —É–º–µ—é—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç (generateContent)
                if 'generateContent' in m.supported_generation_methods:
                    print(f"- {m.name}")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞: {e}")

        # –ö—ç—à –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
        self._location_cache = {}
        self._query_enrichment_cache = {}

    def _generate_with_retry(self, prompt: str, retries=3, temperature=0.3, json_mode=False):
        """–£–º–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å retry –ª–æ–≥–∏–∫–æ–π –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º–æ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π"""
        for attempt in range(retries):
            try:
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞
                config = genai.types.GenerationConfig(
                    temperature=temperature,
                    top_p=0.95,
                    top_k=40,
                    max_output_tokens=4096,  # –£–≤–µ–ª–∏—á–∏–º –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
                    response_mime_type="application/json" if json_mode else "text/plain"
                )

                response = self.model.generate_content(prompt, generation_config=config)
                return response
            except exceptions.ResourceExhausted as e:
                wait_time = 10 * (attempt + 1)
                logger.warning(f"Gemini quota exceeded. Retry {attempt + 1}/{retries} after {wait_time}s")
                time.sleep(wait_time)
            except Exception as e:
                logger.error(f"Gemini error: {e}")
                if attempt == retries - 1:
                    return None
        return None

    @staticmethod
    def _extract_text(response) -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ Gemini"""
        if not response:
            return ""
        try:
            return response.text or ""
        except Exception:
            try:
                candidates = getattr(response, "candidates", [])
                for cand in candidates:
                    content = getattr(cand, "content", None)
                    parts = getattr(content, "parts", [])
                    for part in parts:
                        text = getattr(part, "text", None)
                        if text:
                            return text
            except Exception as e:
                logger.error(f"Failed to extract text: {e}")
        return ""

    def _parse_json_response(self, text: str) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ JSON —Å –ø–æ–∏—Å–∫–æ–º –≥—Ä–∞–Ω–∏—Ü –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Python-—Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞"""
        if not text:
            return None

        try:
            # 1. –ü–æ–∏—Å–∫ –≥—Ä–∞–Ω–∏—Ü JSON (—á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å "Here is your JSON..." –≤ –Ω–∞—á–∞–ª–µ)
            text = text.strip()

            # –ò—â–µ–º –∏–Ω–¥–µ–∫—Å—ã –Ω–∞—á–∞–ª–∞ –æ–±—ä–µ–∫—Ç–∞ –∏–ª–∏ —Å–ø–∏—Å–∫–∞
            start_brace = text.find('{')
            start_bracket = text.find('[')

            start = -1
            end = -1

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —á—Ç–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Ä–∞–Ω—å—à–µ (–æ–±—ä–µ–∫—Ç –∏–ª–∏ —Å–ø–∏—Å–æ–∫) –∏ –∏—â–µ–º –∫–æ–Ω–µ—Ü
            if start_brace != -1 and (start_bracket == -1 or start_brace < start_bracket):
                start = start_brace
                end = text.rfind('}') + 1
            elif start_bracket != -1 and (start_brace == -1 or start_bracket < start_brace):
                start = start_bracket
                end = text.rfind(']') + 1

            if start != -1 and end > start:
                json_str = text[start:end]
            else:
                # –ï—Å–ª–∏ —Å–∫–æ–±–æ–∫ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º —á–∏—Å—Ç–∏—Ç—å –∫–∞–∫ –±—ã–ª–æ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
                json_str = text.replace('```json', '').replace('```', '').strip()

            # 2. –ß–∏—Å—Ç–∫–∞ –≤–∏—Å—è—á–∏—Ö –∑–∞–ø—è—Ç—ã—Ö (Regex)
            json_str = re.sub(r',\s*]', ']', json_str)
            json_str = re.sub(r',\s*}', '}', json_str)

            # 3. –ü–æ–ø—ã—Ç–∫–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ JSON –ø–∞—Ä—Å–∏–Ω–≥–∞
            return json.loads(json_str)

        except json.JSONDecodeError:
            try:
                # 4. FALLBACK: Python eval
                # –°–ø–∞—Å–∞–µ—Ç, –µ—Å–ª–∏ AI –≤–µ—Ä–Ω—É–ª –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏: {'key': 'value'}
                return ast.literal_eval(json_str)
            except Exception:
                # 5. –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –û–®–ò–ë–ö–ò
                # –≠—Ç–æ —Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ: –º—ã —É–≤–∏–¥–∏–º –≤ –∫–æ–Ω—Å–æ–ª–∏, –∫–∞–∫–æ–π –∏–º–µ–Ω–Ω–æ —Ç–µ–∫—Å—Ç —Å–ª–æ–º–∞–ª –ø–∞—Ä—Å–µ—Ä
                logger.error(f"‚ùå JSON Parse Failed. Bad text content:\n{text}")
                return None
        except Exception as e:
            logger.error(f"‚ùå Unexpected Error in JSON parser: {e}")
            return None

    # ======================== STAGE 1: INTENT CLASSIFICATION ========================

    def classify_intent(self, user_message: str, context: Dict = None) -> Dict:
        """
        –ü–µ—Ä–≤—ã–π —ç—Ç–∞–ø: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —á—Ç–æ —Ö–æ—á–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –∏—Å–∫–∞—Ç—å, –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∏–ª–∏ —Å–≤—è–∑–∞—Ç—å—Å—è.
        """
        context_info = json.dumps(context or {}, ensure_ascii=False)

        prompt = f"""–¢—ã ‚Äî HomeMe AI, —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∑–∞–ø—Ä–æ—Å–æ–≤ –æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏.

–ó–ê–î–ê–ß–ê: –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–º–µ—Ä–µ–Ω–∏–µ (intent) –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–í–û–ó–ú–û–ñ–ù–´–ï –ò–ù–¢–ï–ù–¢–´:
1. "search_objects" - –•–æ—á–µ—Ç –Ω–∞–π—Ç–∏/–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–≤–∞—Ä—Ç–∏—Ä—ã
2. "consult_location" - –°–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ —Ä–∞–π–æ–Ω–µ/–ª–æ–∫–∞—Ü–∏–∏ (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å)
3. "contact_expert" - –•–æ—á–µ—Ç —Å–≤—è–∑–∞—Ç—å—Å—è —Å –∂–∏–≤—ã–º —ç–∫—Å–ø–µ—Ä—Ç–æ–º
4. "greeting" - –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–ª–∏ –æ–±—â–∞—è –±–µ—Å–µ–¥–∞
5. "refine_search" - –£—Ç–æ—á–Ω–µ–Ω–∏–µ/–∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ–∏—Å–∫–∞

–ö–û–ù–¢–ï–ö–°–¢ –î–ò–ê–õ–û–ì–ê: {context_info}
–°–û–û–ë–©–ï–ù–ò–ï: "{user_message}"

–í–µ—Ä–Ω–∏ JSON:
{{
    "intent": "search_objects",
    "confidence": 0.95,
    "reasoning": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø–æ–∏—Å–∫ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏",
    "is_continuation": false
}}"""

        response = self._generate_with_retry(prompt, temperature=0.2)
        text = self._extract_text(response)
        result = self._parse_json_response(text)

        if not result:
            return {
                "intent": "greeting",
                "confidence": 0.3,
                "reasoning": "–ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å",
                "is_continuation": False
            }

        return result

    # ======================== STAGE 2: GEOGRAPHIC INTELLIGENCE ========================

    def resolve_location_intelligence(self, user_message: str, context: Dict = None) -> Dict:
        """
        –í—Ç–æ—Ä–æ–π —ç—Ç–∞–ø: –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞—Ü–∏–π.
        AI —Å–∞–º –ø–æ–Ω–∏–º–∞–µ—Ç EXPO, –õ–µ–≤—ã–π –±–µ—Ä–µ–≥, "—Ä—è–¥–æ–º —Å Mega" –∏ —Ç.–¥.
        """
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏, –ø–æ—ç—Ç–æ–º—É –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        context = context or {}
        cache_key = f"{user_message[:50]}_{context.get('city', '')}"
        if cache_key in self._location_cache:
            return self._location_cache[cache_key]

        context_info = json.dumps(context, ensure_ascii=False)

        prompt = f"""–¢—ã ‚Äî –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π AI-—ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≥–æ—Ä–æ–¥–∞–º –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞ (–ê—Å—Ç–∞–Ω–∞, –ê–ª–º–∞—Ç—ã, –®—ã–º–∫–µ–Ω—Ç, –ê—Ç—ã—Ä–∞—É).

–ó–ê–î–ê–ß–ê: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏ –æ–±–æ–≥–∞—Ç–∏—Ç—å –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–ì–û–†–û–î–ê (—Ç–æ–ª—å–∫–æ —ç—Ç–∏):
- Astana (–ê—Å—Ç–∞–Ω–∞, –ù—É—Ä—Å—É–ª—Ç–∞–Ω)
- Almaty (–ê–ª–º–∞—Ç—ã)
- Shymkent (–®—ã–º–∫–µ–Ω—Ç)
- Atyrau (–ê—Ç—ã—Ä–∞—É)

–ò–ó–í–ï–°–¢–ù–´–ï –†–ê–ô–û–ù–´ –ê–°–¢–ê–ù–´:
- –ï—Å–∏–ª—å—Å–∫–∏–π —Ä–∞–π–æ–Ω (–õ–µ–≤—ã–π –±–µ—Ä–µ–≥, Yesil, Esil) - –Ω–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä, EXPO, Mega Silk Way, –ë–∞–π—Ç–µ—Ä–µ–∫
- –°–∞—Ä—ã–∞—Ä–∫–∏–Ω—Å–∫–∏–π —Ä–∞–π–æ–Ω (–ü—Ä–∞–≤—ã–π –±–µ—Ä–µ–≥) - —Å—Ç–∞—Ä—ã–π –≥–æ—Ä–æ–¥, —Ä—ã–Ω–∫–∏
- –ê–ª–º–∞—Ç–∏–Ω—Å–∫–∏–π —Ä–∞–π–æ–Ω - –∂–∏–ª—ã–µ –º–∞—Å—Å–∏–≤—ã
- –ë–∞–π–∫–æ–Ω—É—Ä—Å–∫–∏–π —Ä–∞–π–æ–Ω - –ø—Ä–æ–º–∑–æ–Ω–∞, –∂–∏–ª—å–µ

–ò–ó–í–ï–°–¢–ù–´–ï –õ–û–ö–ê–¶–ò–ò –ê–°–¢–ê–ù–´:
- EXPO - –ï—Å–∏–ª—å—Å–∫–∏–π —Ä-–Ω, –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω—Ç—Ä, –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã ~51.091, 71.417
- Mega Silk Way - —Ä—è–¥–æ–º —Å EXPO
- –•–∞–Ω –®–∞—Ç—ã—Ä - —Ü–µ–Ω—Ç—Ä
- –ù–∞–∑–∞—Ä–±–∞–µ–≤ –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç - —Ä—è–¥–æ–º —Å EXPO
- –ë–æ—Ç–∞–Ω–∏—á–µ—Å–∫–∏–π —Å–∞–¥ - —Å–µ–≤–µ—Ä –≥–æ—Ä–æ–¥–∞

–ê–õ–ú–ê–¢–´:
- –ê–ª–º–∞–ª–∏–Ω—Å–∫–∏–π —Ä–∞–π–æ–Ω - —Ü–µ–Ω—Ç—Ä, –ê—Ä–±–∞—Ç
- –ú–µ–¥–µ—É—Å–∫–∏–π —Ä–∞–π–æ–Ω - —ç–ª–∏—Ç–Ω—ã–π, –≥–æ—Ä—ã
- –ë–æ—Å—Ç–∞–Ω–¥—ã–∫—Å–∫–∏–π - –¥–µ–ª–æ–≤–æ–π
- –ê—É—ç–∑–æ–≤—Å–∫–∏–π - –∂–∏–ª–æ–π –º–∞—Å—Å–∏–≤

–ü–†–ê–í–ò–õ–ê:
1. –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å < 0.4, –≤–æ–∑–≤—Ä–∞—â–∞–π city=null, district=null
2. EXPO –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ = Astana + –ï—Å–∏–ª—å—Å–∫–∏–π —Ä–∞–π–æ–Ω
3. "–õ–µ–≤—ã–π –±–µ—Ä–µ–≥" = Astana + –ï—Å–∏–ª—å—Å–∫–∏–π
4. –û—Ä–∏–µ–Ω—Ç–∏—Ä—ã (–ø–∞—Ä–∫, –º–µ—Ç—Ä–æ, –¢–¶) –¥–æ–±–∞–≤–ª—è–π –≤ nearby_landmarks
5. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∞–¥—Ä–µ—Å–∞ - —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å

–ö–û–ù–¢–ï–ö–°–¢: {context_info}
–ó–ê–ü–†–û–°: "{user_message}"

–í–µ—Ä–Ω–∏ JSON:
{{
    "city": "Astana",
    "city_confidence": 0.95,
    "district": "–ï—Å–∏–ª—å—Å–∫–∏–π —Ä–∞–π–æ–Ω",
    "district_normalized": "Yesil District",
    "nearby_landmarks": ["EXPO", "Mega Silk Way"],
    "coordinates_estimate": {{"lat": 51.091, "lon": 71.417}},
    "radius_km": 5.0,
    "confidence": 0.88,
    "reasoning": "–£–ø–æ–º—è–Ω—É—Ç EXPO, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ï—Å–∏–ª—å—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ –ê—Å—Ç–∞–Ω—ã"
}}"""

        response = self._generate_with_retry(prompt, temperature=0.1)
        text = self._extract_text(response)
        result = self._parse_json_response(text)

        if not result or result.get('confidence', 0) < 0.4:
            return {
                "city": None,
                "district": None,
                "confidence": 0.0,
                "reasoning": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ª–æ–∫–∞—Ü–∏—é —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é"
            }

        self._location_cache[cache_key] = result
        return result

    # ======================== STAGE 3: LIFESTYLE & PREFERENCES EXTRACTION ========================

    def extract_lifestyle_preferences(self, user_message: str, context: Dict = None) -> Dict:
        """
        –¢—Ä–µ—Ç–∏–π —ç—Ç–∞–ø: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ lifestyle-–ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –∏ –Ω–µ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π.
        "–¢–∏—Ö–æ", "–¥–ª—è —Å–µ–º—å–∏", "—Ä—è–¥–æ–º —Å –º–µ—Ç—Ä–æ", "–∑–µ–ª–µ–Ω—ã–π —Ä–∞–π–æ–Ω" –∏ —Ç.–¥.
        """
        prompt = f"""–¢—ã ‚Äî AI-–ø—Å–∏—Ö–æ–ª–æ–≥ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å lifestyle-–ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è.

–ö–ê–¢–ï–ì–û–†–ò–ò –ü–†–ï–î–ü–û–ß–¢–ï–ù–ò–ô:

1. –ê–¢–ú–û–°–§–ï–†–ê:
   - quiet (—Ç–∏—Ö–æ, —Å–ø–æ–∫–æ–π–Ω–æ)
   - lively (–æ–∂–∏–≤–ª–µ–Ω–Ω–æ, —Ü–µ–Ω—Ç—Ä)
   - nature (–∑–µ–ª–µ–Ω–æ, –ø–∞—Ä–∫–∏)
   - urban (–≥–æ—Ä–æ–¥—Å–∫–æ–π —Å—Ç–∏–ª—å)

2. –ò–ù–§–†–ê–°–¢–†–£–ö–¢–£–†–ê:
   - metro (–º–µ—Ç—Ä–æ —Ä—è–¥–æ–º)
   - school (—à–∫–æ–ª—ã, –¥–µ—Ç—Å–∞–¥—ã)
   - mall (–¢–¶, –º–∞–≥–∞–∑–∏–Ω—ã)
   - medical (–ø–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∏)
   - park (–ø–∞—Ä–∫–∏, —Å–∫–≤–µ—Ä—ã)
   - gym (—Å–ø–æ—Ä—Ç–∑–∞–ª—ã)

3. –¶–ï–õ–ï–í–ê–Ø –ê–£–î–ò–¢–û–†–ò–Ø:
   - family (—Å–µ–º—å—è —Å –¥–µ—Ç—å–º–∏)
   - student (—Å—Ç—É–¥–µ–Ω—Ç)
   - young_professional (–º–æ–ª–æ–¥–æ–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç)
   - investor (–∏–Ω–≤–µ—Å—Ç–æ—Ä)
   - retiree (–ø–µ–Ω—Å–∏–æ–Ω–µ—Ä)

4. –û–°–û–ë–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
   - view (–∫—Ä–∞—Å–∏–≤—ã–π –≤–∏–¥)
   - new_building (–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞)
   - renovation (—Å —Ä–µ–º–æ–Ω—Ç–æ–º)
   - parking (–ø–∞—Ä–∫–æ–≤–∫–∞)
   - security (–æ—Ö—Ä–∞–Ω–∞)

–ó–ê–ü–†–û–°: "{user_message}"

–ò–∑–≤–ª–µ–∫–∏ –º–∞–∫—Å–∏–º—É–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –≤–µ—Ä–Ω–∏ JSON:
{{
    "lifestyle_tags": ["quiet", "family", "park", "school"],
    "priority_tags": ["quiet", "park"],
    "extracted_phrases": ["–≥–¥–µ —Ç–∏—Ö–æ", "–¥–ª—è —Å–µ–º—å–∏"],
    "target_audience": "family",
    "confidence": 0.75,
    "reasoning": "–ó–∞–ø—Ä–æ—Å —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å–µ–º–µ–π–Ω—ã–µ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ç–∏—à–∏–Ω—É"
}}"""

        response = self._generate_with_retry(prompt, temperature=0.3, json_mode=True)
        text = self._extract_text(response)
        result = self._parse_json_response(text)

        return result or {"lifestyle_tags": [], "confidence": 0.0}

    # ======================== STAGE 4: PARAMETER EXTRACTION ========================

    def extract_search_parameters(self, user_message: str, context: Dict = None) -> Dict:
        """
        –ß–µ—Ç–≤–µ—Ä—Ç—ã–π —ç—Ç–∞–ø: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ–∏—Å–∫–∞.
        –¶–µ–Ω–∞, –∫–æ–º–Ω–∞—Ç—ã, –ø–ª–æ—â–∞–¥—å –∏ —Ç.–¥.
        """
        context_info = json.dumps(context or {}, ensure_ascii=False)

        prompt = f"""–¢—ã ‚Äî AI-–∞–Ω–∞–ª–∏—Ç–∏–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏.

–ò–ó–í–õ–ï–ö–ê–ï–ú–´–ï –ü–ê–†–ê–ú–ï–¢–†–´:
1. rooms (int) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç (1, 2, 3, 4+)
2. min_price / max_price (int) - –±—é–¥–∂–µ—Ç –≤ —Ç–µ–Ω–≥–µ
3. min_area / max_area (float) - –ø–ª–æ—â–∞–¥—å –≤ –º¬≤
4. floor_preferences (list) - –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ —ç—Ç–∞–∂—É ["not_first", "not_last", "high"]
5. property_type (str) - "new_building", "secondary", "any"

–†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–ï –§–û–†–ú–£–õ–ò–†–û–í–û–ö:
- "–¥–≤—É—à–∫–∞" = 2 –∫–æ–º–Ω–∞—Ç—ã
- "–¥–æ 50 –ª—è–º–æ–≤" = max_price: 50000000
- "40-50 –∫–≤–∞–¥—Ä–∞—Ç–æ–≤" = min_area: 40, max_area: 50
- "–Ω–µ –ø–µ—Ä–≤—ã–π —ç—Ç–∞–∂" = floor_preferences: ["not_first"]

–ö–û–ù–¢–ï–ö–°–¢: {context_info}
–ó–ê–ü–†–û–°: "{user_message}"

–í–µ—Ä–Ω–∏ JSON:
{{
    "rooms": 2,
    "max_price": 50000000,
    "min_area": 40,
    "max_area": 60,
    "floor_preferences": ["not_first"],
    "property_type": "any",
    "confidence": 0.85,
    "extracted_entities": {{"rooms": "–¥–≤—É—à–∫–∞", "price": "–¥–æ 50 –º–ª–Ω"}}
}}"""

        response = self._generate_with_retry(prompt, temperature=0.2)
        text = self._extract_text(response)
        result = self._parse_json_response(text)

        return result or {"confidence": 0.0}

    # ======================== STAGE 5: QUERY ENRICHMENT & SEMANTIC EXPANSION ========================

    def enrich_search_query(self, user_message: str, location_data: Dict,
                            lifestyle_data: Dict, params_data: Dict) -> Dict:
        """
        –ü—è—Ç—ã–π —ç—Ç–∞–ø: —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —É–º–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏–Ω–æ–Ω–∏–º—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∫–ª—é—á–∏.
        """
        combined_context = {
            "location": location_data,
            "lifestyle": lifestyle_data,
            "params": params_data
        }
        context_str = json.dumps(combined_context, ensure_ascii=False)

        prompt = f"""–¢—ã ‚Äî AI –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.

–ó–ê–î–ê–ß–ê: –°–æ–∑–¥–∞—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –ø–æ–∏—Å–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
{context_str}

–û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –ó–ê–ü–†–û–°: "{user_message}"

–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π:
1. semantic_keywords - –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
2. description_match_phrases - —Ñ—Ä–∞–∑—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –æ–ø–∏—Å–∞–Ω–∏—è—Ö
3. exclusion_keywords - —á—Ç–æ —Ç–æ—á–Ω–æ –ù–ï –ø–æ–¥—Ö–æ–¥–∏—Ç
4. embedding_text - –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏

–ü–†–ò–ú–ï–†:
–ï—Å–ª–∏ "—Ç–∏—Ö–∞—è –∫–≤–∞—Ä—Ç–∏—Ä–∞ —Ä—è–¥–æ–º —Å –ø–∞—Ä–∫–æ–º –¥–ª—è —Å–µ–º—å–∏":
- semantic_keywords: ["—Ç–∏—Ö–∏–π", "—Å–ø–æ–∫–æ–π–Ω—ã–π", "–∑–µ–ª–µ–Ω—ã–π", "–ø–∞—Ä–∫", "—Å–∫–≤–µ—Ä", "—Å–µ–º–µ–π–Ω—ã–π", "–¥–µ—Ç—Å–∫–∞—è –ø–ª–æ—â–∞–¥–∫–∞"]
- description_match_phrases: ["—Ç–∏—Ö–∏–π —Ä–∞–π–æ–Ω", "—Ä—è–¥–æ–º –ø–∞—Ä–∫", "–¥–ª—è —Å–µ–º—å–∏", "–¥–µ—Ç—Å–∫–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞"]
- exclusion_keywords: ["—à—É–º–Ω—ã–π", "–Ω–æ—á–Ω–æ–π –∫–ª—É–±", "—Ç—Ä–∞—Å—Å–∞"]

–í–µ—Ä–Ω–∏ JSON:
{{
    "semantic_keywords": ["—Ç–∏—Ö–∏–π", "–ø–∞—Ä–∫"],
    "description_match_phrases": ["—Ç–∏—Ö–∏–π —Ä–∞–π–æ–Ω", "–∑–µ–ª–µ–Ω–∞—è –∑–æ–Ω–∞"],
    "exclusion_keywords": ["—à—É–º–Ω—ã–π"],
    "embedding_text": "–¢–∏—Ö–∞—è —Å–ø–æ–∫–æ–π–Ω–∞—è –∫–≤–∞—Ä—Ç–∏—Ä–∞ –≤ –∑–µ–ª–µ–Ω–æ–º —Ä–∞–π–æ–Ω–µ —Ä—è–¥–æ–º —Å –ø–∞—Ä–∫–æ–º –¥–ª—è —Å–µ–º—å–∏ —Å –¥–µ—Ç—å–º–∏",
    "search_weight_factors": {{
        "location_weight": 0.4,
        "lifestyle_weight": 0.35,
        "params_weight": 0.25
    }}
}}"""

        response = self._generate_with_retry(prompt, temperature=0.4)
        text = self._extract_text(response)
        result = self._parse_json_response(text)

        return result or {"embedding_text": user_message}

    # ======================== MASTER ORCHESTRATION ========================

    def analyze_query_comprehensive(self, user_message: str, context: Dict = None) -> Dict:
        """
        –ì–õ–ê–í–ù–´–ô –ú–ï–¢–û–î: –û—Ä–∫–µ—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤—Å–µ —ç—Ç–∞–ø—ã –∞–Ω–∞–ª–∏–∑–∞.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        """
        logger.info(f"üß† Starting comprehensive analysis for: {user_message[:50]}...")

        # Stage 1: Intent
        intent_result = self.classify_intent(user_message, context)
        logger.info(f"üìå Intent: {intent_result.get('intent')} (conf: {intent_result.get('confidence')})")

        # –ï—Å–ª–∏ –Ω–µ –ø–æ–∏—Å–∫ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if intent_result.get('intent') not in ['search_objects', 'refine_search']:
            return {
                "intent": intent_result.get('intent'),
                "confidence": intent_result.get('confidence'),
                "stage": "intent_only"
            }

        # Stage 2: Location Intelligence
        location_result = self.resolve_location_intelligence(user_message, context)
        logger.info(f"üìç Location: {location_result.get('city')}, {location_result.get('district')}")

        # Stage 3: Lifestyle
        lifestyle_result = self.extract_lifestyle_preferences(user_message, context)
        logger.info(f"üéØ Lifestyle tags: {lifestyle_result.get('lifestyle_tags', [])}")

        # Stage 4: Parameters
        params_result = self.extract_search_parameters(user_message, context)
        logger.info(f"üìä Params: {params_result}")

        # Stage 5: Semantic Enrichment
        enrichment_result = self.enrich_search_query(
            user_message, location_result, lifestyle_result, params_result
        )
        logger.info(f"‚ú® Enrichment completed")

        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        comprehensive_result = {
            "intent": intent_result.get('intent'),
            "intent_confidence": intent_result.get('confidence'),

            # Location
            "city": location_result.get('city'),
            "district": location_result.get('district'),
            "nearby_landmarks": location_result.get('nearby_landmarks', []),
            "coordinates": location_result.get('coordinates_estimate'),
            "radius_km": location_result.get('radius_km'),
            "location_confidence": location_result.get('confidence', 0),

            # Parameters
            "rooms": params_result.get('rooms'),
            "max_price": params_result.get('max_price'),
            "min_price": params_result.get('min_price'),
            "min_area": params_result.get('min_area'),
            "max_area": params_result.get('max_area'),
            "floor_preferences": params_result.get('floor_preferences', []),
            "property_type": params_result.get('property_type'),

            # Lifestyle
            "lifestyle_tags": lifestyle_result.get('lifestyle_tags', []),
            "priority_tags": lifestyle_result.get('priority_tags', []),
            "target_audience": lifestyle_result.get('target_audience'),

            # Enrichment
            "semantic_keywords": enrichment_result.get('semantic_keywords', []),
            "description_match_phrases": enrichment_result.get('description_match_phrases', []),
            "exclusion_keywords": enrichment_result.get('exclusion_keywords', []),
            "embedding_text": enrichment_result.get('embedding_text', user_message),

            # Overall
            "analysis_complete": True,
            "stage": "comprehensive"
        }

        logger.info(f"‚úÖ Comprehensive analysis complete!")
        return comprehensive_result

    # ======================== EMBEDDINGS ========================

    def get_embedding(self, text: str):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        try:
            result = genai.embed_content(
                model="models/text-embedding-004",
                content=text,
                task_type="retrieval_document"
            )
            embedding = result.get('embedding')

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ truth value –¥–ª—è numpy array
            if embedding is None:
                return None

            return list(embedding)
        except Exception as e:
            logger.error(f"Embedding error: {e}")
            return None

    # ======================== CONSULTATION (RAG) ========================

    def generate_consultation(self, query: str, location_info: Dict = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ø–æ —Ä–∞–π–æ–Ω—É"""
        location_context = json.dumps(location_info or {}, ensure_ascii=False)

        prompt = f"""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞.

–ö–û–ù–¢–ï–ö–°–¢ –õ–û–ö–ê–¶–ò–ò: {location_context}
–í–û–ü–†–û–°: "{query}"

–î–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é:
1. –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–π–æ–Ω–∞/–ª–æ–∫–∞—Ü–∏–∏
2. –ü–ª—é—Å—ã (3-4 –ø—É–Ω–∫—Ç–∞)
3. –ú–∏–Ω—É—Å—ã (2-3 –ø—É–Ω–∫—Ç–∞)
4. –î–ª—è –∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∏—Ç
5. –°—Ä–µ–¥–Ω–∏–µ —Ü–µ–Ω—ã (–µ—Å–ª–∏ –∑–Ω–∞–µ—à—å)

–°—Ç–∏–ª—å: –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç, —á–µ—Å—Ç–Ω—ã–π, –±–µ–∑ –ø—Ä–µ—É–≤–µ–ª–∏—á–µ–Ω–∏–π."""

        response = self._generate_with_retry(prompt, temperature=0.6)
        return self._extract_text(response) or "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é."
